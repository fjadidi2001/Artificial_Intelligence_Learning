{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOry9YAiWFol8yblIwLwAls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Artificial_Intelligence_Learning/blob/master/_3soft_computing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33aIIglBouBD",
        "outputId": "5ec33254-6d78-4e11-ded4-4a0b93fe9fc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Position: 0.002200958464137287\n",
            "Best Value: -0.9530856155903941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-6a37c5e938de>:5: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return x**3 + np.sqrt(x) - 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to minimize\n",
        "def objective_function(x):\n",
        "    return x**3 + np.sqrt(x) - 1\n",
        "\n",
        "# Particle Swarm Optimization (PSO) algorithm\n",
        "def pso_algorithm(num_particles, num_iterations, w1, w2, w3):\n",
        "    # Initialize particles with random positions and velocities\n",
        "    particles_position = np.random.uniform(0, 10, num_particles)\n",
        "    particles_velocity = np.random.uniform(-1, 1, num_particles)\n",
        "\n",
        "    # Initialize best positions and values\n",
        "    personal_best_positions = particles_position.copy()\n",
        "    personal_best_values = objective_function(personal_best_positions)\n",
        "\n",
        "    # Initialize global best position and value\n",
        "    global_best_position = particles_position[np.argmin(personal_best_values)]\n",
        "    global_best_value = min(personal_best_values)\n",
        "\n",
        "    # PSO main loop\n",
        "    for iteration in range(num_iterations):\n",
        "        for i in range(num_particles):\n",
        "            # Update particle velocity and position\n",
        "            r1, r2 = np.random.rand(), np.random.rand()\n",
        "            particles_velocity[i] = w1 * particles_velocity[i] + w2 * r1 * (personal_best_positions[i] - particles_position[i]) + w3 * r2 * (global_best_position - particles_position[i])\n",
        "            particles_position[i] += particles_velocity[i]\n",
        "\n",
        "            # Update personal best\n",
        "            current_value = objective_function(particles_position[i])\n",
        "            if current_value < personal_best_values[i]:\n",
        "                personal_best_values[i] = current_value\n",
        "                personal_best_positions[i] = particles_position[i]\n",
        "\n",
        "                # Update global best\n",
        "                if current_value < global_best_value:\n",
        "                    global_best_value = current_value\n",
        "                    global_best_position = particles_position[i]\n",
        "\n",
        "    return global_best_position, global_best_value\n",
        "\n",
        "# Parameters\n",
        "num_particles = 20\n",
        "num_iterations = 100\n",
        "w1, w2, w3 = 1, 1, 1\n",
        "\n",
        "# Run PSO algorithm\n",
        "best_position, best_value = pso_algorithm(num_particles, num_iterations, w1, w2, w3)\n",
        "\n",
        "print(\"Best Position:\", best_position)\n",
        "print(\"Best Value:\", best_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Modified objective function to handle non-negative values\n",
        "def objective_function(x):\n",
        "    return x**3 + np.sqrt(np.maximum(x, 0)) - 1\n",
        "import numpy as np\n",
        "\n",
        "# Modified objective function to handle non-negative values\n",
        "def objective_function(x):\n",
        "    return x**3 + np.sqrt(np.maximum(x, 0)) - 1\n",
        "# Particle Swarm Optimization (PSO) algorithm\n",
        "def pso_algorithm(num_particles, num_iterations, w1, w2, w3):\n",
        "    # Initialize particles with random positions and velocities\n",
        "    particles_position = np.random.uniform(0, 10, num_particles)\n",
        "    particles_velocity = np.random.uniform(-1, 1, num_particles)\n",
        "\n",
        "    # Initialize best positions and values\n",
        "    personal_best_positions = particles_position.copy()\n",
        "    personal_best_values = objective_function(personal_best_positions)\n",
        "\n",
        "    # Initialize global best position and value\n",
        "    global_best_position = particles_position[np.argmin(personal_best_values)]\n",
        "    global_best_value = min(personal_best_values)\n",
        "\n",
        "    # PSO main loop\n",
        "    for iteration in range(num_iterations):\n",
        "        for i in range(num_particles):\n",
        "            # Update particle velocity and position\n",
        "            r1, r2 = np.random.rand(), np.random.rand()\n",
        "            particles_velocity[i] = w1 * particles_velocity[i] + w2 * r1 * (personal_best_positions[i] - particles_position[i]) + w3 * r2 * (global_best_position - particles_position[i])\n",
        "            particles_position[i] += particles_velocity[i]\n",
        "\n",
        "            # Update personal best\n",
        "            current_value = objective_function(particles_position[i])\n",
        "            if current_value < personal_best_values[i]:\n",
        "                personal_best_values[i] = current_value\n",
        "                personal_best_positions[i] = particles_position[i]\n",
        "\n",
        "                # Update global best\n",
        "                if current_value < global_best_value:\n",
        "                    global_best_value = current_value\n",
        "                    global_best_position = particles_position[i]\n",
        "\n",
        "    return global_best_position, global_best_value\n",
        "\n",
        "# Parameters\n",
        "num_particles = 20\n",
        "num_iterations = 100\n",
        "w1, w2, w3 = 1, 1, 1\n",
        "\n",
        "# Run PSO algorithm\n",
        "best_position, best_value = pso_algorithm(num_particles, num_iterations, w1, w2, w3)\n",
        "\n",
        "print(\"Best Position:\", best_position)\n",
        "print(\"Best Value:\", best_value)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5XESrbnqkQn",
        "outputId": "31c82cf9-0fa3-4ea0-d895-229f4a759171"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Position: -4.049355053504197e+39\n",
            "Best Value: -6.63983938489047e+118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Modified objective function to handle non-negative values\n",
        "def objective_function(x):\n",
        "    return x**3 + np.sqrt(np.maximum(x, 0)) - 1\n",
        "\n",
        "# Particle Swarm Optimization (PSO) algorithm\n",
        "def pso_algorithm(num_particles, num_iterations, w1, w2, w3):\n",
        "    # Initialize particles with random positions and velocities\n",
        "    particles_position = np.random.uniform(0, 10, num_particles)\n",
        "    particles_velocity = np.random.uniform(-1, 1, num_particles)\n",
        "\n",
        "    # Initialize best positions and values\n",
        "    personal_best_positions = particles_position.copy()\n",
        "    personal_best_values = objective_function(personal_best_positions)\n",
        "\n",
        "    # Initialize global best position and value\n",
        "    global_best_position = particles_position[np.argmin(personal_best_values)]\n",
        "    global_best_value = min(personal_best_values)\n",
        "\n",
        "    # PSO main loop\n",
        "    for iteration in range(num_iterations):\n",
        "        for i in range(num_particles):\n",
        "            # Update particle velocity and position\n",
        "            r1, r2 = np.random.rand(), np.random.rand()\n",
        "            particles_velocity[i] = w1 * particles_velocity[i] + w2 * r1 * (personal_best_positions[i] - particles_position[i]) + w3 * r2 * (global_best_position - particles_position[i])\n",
        "            particles_position[i] += particles_velocity[i]\n",
        "\n",
        "            # Update personal best\n",
        "            current_value = objective_function(particles_position[i])\n",
        "            if current_value < personal_best_values[i]:\n",
        "                personal_best_values[i] = current_value\n",
        "                personal_best_positions[i] = particles_position[i]\n",
        "\n",
        "                # Update global best\n",
        "                if current_value < global_best_value:\n",
        "                    global_best_value = current_value\n",
        "                    global_best_position = particles_position[i]\n",
        "\n",
        "        # Print best position and value for the first 5 epochs\n",
        "        if iteration < 100:\n",
        "            print(f\"Epoch {iteration + 1}: Best Position - {global_best_position}, Best Value - {global_best_value}\")\n",
        "\n",
        "    return global_best_position, global_best_value\n",
        "\n",
        "# Parameters\n",
        "num_particles = 20\n",
        "num_iterations = 100\n",
        "w1, w2, w3 = 1, 1, 1\n",
        "\n",
        "# Run PSO algorithm\n",
        "best_position, best_value = pso_algorithm(num_particles, num_iterations, w1, w2, w3)\n",
        "\n",
        "print(\"\\nFinal Result:\")\n",
        "print(\"Best Position:\", best_position)\n",
        "print(\"Best Value:\", best_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flSjg0W6rM5o",
        "outputId": "80e4c3c4-cb88-423b-840f-bb6a3aeeb679"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Best Position - -0.28251816314671774, Best Value - -1.0225496145024793\n",
            "Epoch 2: Best Position - -11.153805873202849, Best Value - -1388.6158265811498\n",
            "Epoch 3: Best Position - -54.70533534386901, Best Value - -163716.21915851618\n",
            "Epoch 4: Best Position - -136.4104732178101, Best Value - -2538302.1502808826\n",
            "Epoch 5: Best Position - -265.9921104885455, Best Value - -18819422.35885311\n",
            "Epoch 6: Best Position - -659.4897226556291, Best Value - -286829685.9917855\n",
            "Epoch 7: Best Position - -1535.40466752237, Best Value - -3619666593.3604307\n",
            "Epoch 8: Best Position - -2928.0502279813727, Best Value - -25103574616.33961\n",
            "Epoch 9: Best Position - -6625.036426890083, Best Value - -290780187049.2902\n",
            "Epoch 10: Best Position - -13271.909749206381, Best Value - -2337761808028.762\n",
            "Epoch 11: Best Position - -41680.76674882862, Best Value - -72411425745233.67\n",
            "Epoch 12: Best Position - -107853.79227509345, Best Value - -1254602822215051.0\n",
            "Epoch 13: Best Position - -335701.9892184438, Best Value - -3.783221281885916e+16\n",
            "Epoch 14: Best Position - -831701.0847724453, Best Value - -5.753098421082372e+17\n",
            "Epoch 15: Best Position - -1988297.1126828026, Best Value - -7.860385494823959e+18\n",
            "Epoch 16: Best Position - -3853680.976876445, Best Value - -5.723046538690239e+19\n",
            "Epoch 17: Best Position - -9513569.169882001, Best Value - -8.610541027315213e+20\n",
            "Epoch 18: Best Position - -26122839.64771265, Best Value - -1.7826297646325745e+22\n",
            "Epoch 19: Best Position - -84486722.91911873, Best Value - -6.030667646545743e+23\n",
            "Epoch 20: Best Position - -217660220.48847508, Best Value - -1.0311864420631446e+25\n",
            "Epoch 21: Best Position - -507534625.993945, Best Value - -1.3073655312391628e+26\n",
            "Epoch 22: Best Position - -1309005971.6226966, Best Value - -2.2429773259261276e+27\n",
            "Epoch 23: Best Position - -3130576436.0386763, Best Value - -3.068124197896864e+28\n",
            "Epoch 24: Best Position - -10963842993.031929, Best Value - -1.3179181010635263e+30\n",
            "Epoch 25: Best Position - -29519521248.068077, Best Value - -2.5723373831335536e+31\n",
            "Epoch 26: Best Position - -79761920136.78477, Best Value - -5.074424568165242e+32\n",
            "Epoch 27: Best Position - -183972966712.6775, Best Value - -6.226758686454311e+33\n",
            "Epoch 28: Best Position - -437018763697.97595, Best Value - -8.346420331549502e+34\n",
            "Epoch 29: Best Position - -1286695847375.5625, Best Value - -2.1302358932132525e+36\n",
            "Epoch 30: Best Position - -3006722062990.681, Best Value - -2.7181902679670066e+37\n",
            "Epoch 31: Best Position - -7962065419617.225, Best Value - -5.047510427547489e+38\n",
            "Epoch 32: Best Position - -25031661507500.742, Best Value - -1.5684440542132296e+40\n",
            "Epoch 33: Best Position - -58906237103350.625, Best Value - -2.0440138933807535e+41\n",
            "Epoch 34: Best Position - -114821919468851.97, Best Value - -1.5138205901523648e+42\n",
            "Epoch 35: Best Position - -234572906825290.78, Best Value - -1.290724485842341e+43\n",
            "Epoch 36: Best Position - -471252041120911.75, Best Value - -1.0465493993936212e+44\n",
            "Epoch 37: Best Position - -1074450687820597.0, Best Value - -1.2403934512962628e+45\n",
            "Epoch 38: Best Position - -3137838350761003.5, Best Value - -3.0895249016481187e+46\n",
            "Epoch 39: Best Position - -7383277729603676.0, Best Value - -4.0248306862523505e+47\n",
            "Epoch 40: Best Position - -1.8245848751513908e+16, Best Value - -6.074243692831068e+48\n",
            "Epoch 41: Best Position - -3.742194359649191e+16, Best Value - -5.24057595123575e+49\n",
            "Epoch 42: Best Position - -1.2204491452332934e+17, Best Value - -1.8178542617233812e+51\n",
            "Epoch 43: Best Position - -2.9118504626714016e+17, Best Value - -2.468921060855108e+52\n",
            "Epoch 44: Best Position - -6.185323220835633e+17, Best Value - -2.3663947725121925e+53\n",
            "Epoch 45: Best Position - -1.0950281470238874e+18, Best Value - -1.3130336245585295e+54\n",
            "Epoch 46: Best Position - -2.6547887296892303e+18, Best Value - -1.8710693981402374e+55\n",
            "Epoch 47: Best Position - -6.111273787705231e+18, Best Value - -2.2824182025310686e+56\n",
            "Epoch 48: Best Position - -1.4362393842345867e+19, Best Value - -2.96265100270066e+57\n",
            "Epoch 49: Best Position - -3.7850025373651485e+19, Best Value - -5.422487067766518e+58\n",
            "Epoch 50: Best Position - -1.2300233042089175e+20, Best Value - -1.860972772817014e+60\n",
            "Epoch 51: Best Position - -3.0335333786361555e+20, Best Value - -2.791555931838553e+61\n",
            "Epoch 52: Best Position - -9.090843123721461e+20, Best Value - -7.5129844551919405e+62\n",
            "Epoch 53: Best Position - -2.2752108734622964e+21, Best Value - -1.1777821384390757e+64\n",
            "Epoch 54: Best Position - -5.163526255583794e+21, Best Value - -1.37669954541589e+65\n",
            "Epoch 55: Best Position - -1.2684732536090708e+22, Best Value - -2.0410044096162405e+66\n",
            "Epoch 56: Best Position - -2.826444228132462e+22, Best Value - -2.2579860834543022e+67\n",
            "Epoch 57: Best Position - -8.044115694900124e+22, Best Value - -5.205170079474247e+68\n",
            "Epoch 58: Best Position - -2.527270822591187e+23, Best Value - -1.614192593807056e+70\n",
            "Epoch 59: Best Position - -4.4730165024122365e+23, Best Value - -8.949556234803002e+70\n",
            "Epoch 60: Best Position - -1.1578177628515883e+24, Best Value - -1.5521033070003537e+72\n",
            "Epoch 61: Best Position - -3.085870924464686e+24, Best Value - -2.9385512497930574e+73\n",
            "Epoch 62: Best Position - -5.780317890110118e+24, Best Value - -1.9313241435217522e+74\n",
            "Epoch 63: Best Position - -1.676942881233444e+25, Best Value - -4.71579383912283e+75\n",
            "Epoch 64: Best Position - -4.034243638080803e+25, Best Value - -6.565780630387264e+76\n",
            "Epoch 65: Best Position - -1.4346529395022067e+26, Best Value - -2.9528443665389993e+78\n",
            "Epoch 66: Best Position - -3.833223255245461e+26, Best Value - -5.632385123400963e+79\n",
            "Epoch 67: Best Position - -1.2576760040711644e+27, Best Value - -1.9893276752560917e+81\n",
            "Epoch 68: Best Position - -3.0658931154042366e+27, Best Value - -2.8818477341326368e+82\n",
            "Epoch 69: Best Position - -8.439123532151544e+27, Best Value - -6.010243015696573e+83\n",
            "Epoch 70: Best Position - -2.0051629598127984e+28, Best Value - -8.062115592302405e+84\n",
            "Epoch 71: Best Position - -4.868702050663321e+28, Best Value - -1.154089776070091e+86\n",
            "Epoch 72: Best Position - -1.2470515944315033e+29, Best Value - -1.939336922374637e+87\n",
            "Epoch 73: Best Position - -2.666323893390277e+29, Best Value - -1.8955651406307864e+88\n",
            "Epoch 74: Best Position - -6.229887624203754e+29, Best Value - -2.4179128234439557e+89\n",
            "Epoch 75: Best Position - -1.715385646558855e+30, Best Value - -5.047604460138776e+90\n",
            "Epoch 76: Best Position - -4.063537946398802e+30, Best Value - -6.709852278191087e+91\n",
            "Epoch 77: Best Position - -7.76162382929437e+30, Best Value - -4.67581986698238e+92\n",
            "Epoch 78: Best Position - -1.9368860942549177e+31, Best Value - -7.266281915920038e+93\n",
            "Epoch 79: Best Position - -4.4350207288678295e+31, Best Value - -8.723423604301299e+94\n",
            "Epoch 80: Best Position - -9.13840476115957e+31, Best Value - -7.631522169300971e+95\n",
            "Epoch 81: Best Position - -2.2956774833079594e+32, Best Value - -1.209853049997358e+97\n",
            "Epoch 82: Best Position - -5.7632551865994746e+32, Best Value - -1.9142715697428463e+98\n",
            "Epoch 83: Best Position - -1.5362264800575925e+33, Best Value - -3.625481892852632e+99\n",
            "Epoch 84: Best Position - -3.1206256881167903e+33, Best Value - -3.0389603759762597e+100\n",
            "Epoch 85: Best Position - -9.368307611189294e+33, Best Value - -8.222112740337252e+101\n",
            "Epoch 86: Best Position - -1.9024574392248898e+34, Best Value - -6.885648503989051e+102\n",
            "Epoch 87: Best Position - -6.064116453469476e+34, Best Value - -2.2299883710518804e+104\n",
            "Epoch 88: Best Position - -1.6183804517774286e+35, Best Value - -4.2387897161572024e+105\n",
            "Epoch 89: Best Position - -4.852621111288783e+35, Best Value - -1.1426919025064369e+107\n",
            "Epoch 90: Best Position - -1.3714402115577675e+36, Best Value - -2.579470927205973e+108\n",
            "Epoch 91: Best Position - -2.8545869727451996e+36, Best Value - -2.3261078049607174e+109\n",
            "Epoch 92: Best Position - -5.721355879039113e+36, Best Value - -1.8728236612783333e+110\n",
            "Epoch 93: Best Position - -1.3336341409470647e+37, Best Value - -2.3719750396117048e+111\n",
            "Epoch 94: Best Position - -3.703579048783658e+37, Best Value - -5.0800133765842156e+112\n",
            "Epoch 95: Best Position - -8.841888314560098e+37, Best Value - -6.912498889928055e+113\n",
            "Epoch 96: Best Position - -2.5502174291590857e+38, Best Value - -1.6585616860988255e+115\n",
            "Epoch 97: Best Position - -5.214947808693754e+38, Best Value - -1.4182405519809264e+116\n",
            "Epoch 98: Best Position - -1.5016528990786022e+39, Best Value - -3.386169367635548e+117\n",
            "Epoch 99: Best Position - -3.785732587937294e+39, Best Value - -5.42562533783182e+118\n",
            "Epoch 100: Best Position - -1.0504013746677216e+40, Best Value - -1.1589530542482666e+120\n",
            "\n",
            "Final Result:\n",
            "Best Position: -1.0504013746677216e+40\n",
            "Best Value: -1.1589530542482666e+120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def objective_function(x):\n",
        "    return x**3 + np.sqrt(np.maximum(x, 0)) - 1\n",
        "\n",
        "def initialize_particles(num_particles):\n",
        "    particles_position = np.random.uniform(0, 10, num_particles)\n",
        "    particles_velocity = np.random.uniform(-1, 1, num_particles)\n",
        "    personal_best_positions = particles_position.copy()\n",
        "    personal_best_values = objective_function(personal_best_positions)\n",
        "    global_best_position = particles_position[np.argmin(personal_best_values)]\n",
        "    global_best_value = min(personal_best_values)\n",
        "    return particles_position, particles_velocity, personal_best_positions, personal_best_values, global_best_position, global_best_value\n",
        "\n",
        "def update_particles(particles_position, particles_velocity, personal_best_positions, personal_best_values, global_best_position, global_best_value, w1, w2, w3):\n",
        "    for i in range(len(particles_position)):\n",
        "        r1, r2 = np.random.rand(), np.random.rand()\n",
        "        particles_velocity[i] = w1 * particles_velocity[i] + w2 * r1 * (personal_best_positions[i] - particles_position[i]) + w3 * r2 * (global_best_position - particles_position[i])\n",
        "        particles_position[i] += particles_velocity[i]\n",
        "\n",
        "        current_value = objective_function(particles_position[i])\n",
        "\n",
        "        if current_value < personal_best_values[i]:\n",
        "            personal_best_values[i] = current_value\n",
        "            personal_best_positions[i] = particles_position[i]\n",
        "\n",
        "            if current_value < global_best_value:\n",
        "                global_best_value = current_value\n",
        "                global_best_position = particles_position[i]\n",
        "\n",
        "    return particles_position, particles_velocity, personal_best_positions, personal_best_values, global_best_position, global_best_value\n",
        "\n",
        "def pso_algorithm(num_particles, num_iterations, w1, w2, w3):\n",
        "    particles_position, particles_velocity, personal_best_positions, personal_best_values, global_best_position, global_best_value = initialize_particles(num_particles)\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "        particles_position, particles_velocity, personal_best_positions, personal_best_values, global_best_position, global_best_value = update_particles(particles_position, particles_velocity, personal_best_positions, personal_best_values, global_best_position, global_best_value, w1, w2, w3)\n",
        "\n",
        "        if iteration < 5:\n",
        "            print(f\"Epoch {iteration + 1}: Best Position - {global_best_position}, Best Value - {global_best_value}\")\n",
        "\n",
        "    return global_best_position, global_best_value\n",
        "\n",
        "# Parameters\n",
        "num_particles = 20\n",
        "num_iterations = 100\n",
        "w1, w2, w3 = 1, 1, 1\n",
        "\n",
        "# Run PSO algorithm\n",
        "best_position, best_value = pso_algorithm(num_particles, num_iterations, w1, w2, w3)\n",
        "\n",
        "print(\"\\nFinal Result:\")\n",
        "print(\"Best Position:\", best_position)\n",
        "print(\"Best Value:\", best_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnP1ElFEr69G",
        "outputId": "888136d4-b030-4452-f32d-54b7c53576ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Best Position - -0.5768573470281917, Best Value - -1.191957588288969\n",
            "Epoch 2: Best Position - -8.468290524575343, Best Value - -608.2775793343272\n",
            "Epoch 3: Best Position - -41.92592196202803, Best Value - -73697.6700485644\n",
            "Epoch 4: Best Position - -136.24150339715237, Best Value - -2528881.3507340695\n",
            "Epoch 5: Best Position - -397.88327910721654, Best Value - -62989342.096285984\n",
            "\n",
            "Final Result:\n",
            "Best Position: -8.903015182863436e+39\n",
            "Best Value: -7.056857406697e+119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def objective_function(x):\n",
        "    return x**3 + np.sqrt(np.maximum(x, 0)) - 1\n",
        "\n",
        "def initialize_particles(num_particles):\n",
        "    particles_position = np.random.uniform(0, 10, num_particles)\n",
        "    particles_velocity = np.random.uniform(-1, 1, num_particles)\n",
        "    personal_best_positions = particles_position.copy()\n",
        "    personal_best_values = objective_function(personal_best_positions)\n",
        "    global_best_position = particles_position[np.argmin(personal_best_values)]\n",
        "    global_best_value = min(personal_best_values)\n",
        "    return particles_position, particles_velocity, personal_best_positions, personal_best_values, global_best_position, global_best_value\n",
        "\n",
        "def update_particles(particles_position, particles_velocity, personal_best_positions, personal_best_values, global_best_position, global_best_value, w1, w2, w3):\n",
        "    for i in range(len(particles_position)):\n",
        "        r1, r2 = np.random.rand(), np.random.rand()\n",
        "        particles_velocity[i] = w1 * particles_velocity[i] + w2 * r1 * (personal_best_positions[i] - particles_position[i]) + w3 * r2 * (global_best_position - particles_position[i])\n",
        "        particles_position[i] += particles_velocity[i]\n",
        "\n",
        "        current_value = objective_function(particles_position[i])\n",
        "\n",
        "        if current_value < personal_best_values[i]:\n",
        "            personal_best_values[i] = current_value\n",
        "            personal_best_positions[i] = particles_position[i]\n",
        "\n",
        "            if current_value < global_best_value:\n",
        "                global_best_value = current_value\n",
        "                global_best_position = particles_position[i]\n",
        "\n",
        "    return particles_position, particles_velocity, personal_best_positions, personal_best_values, global_best_position, global_best_value\n",
        "\n",
        "def pso_algorithm(num_particles, num_iterations, w1, w2, w3):\n",
        "    particles_position, particles_velocity, personal_best_positions, personal_best_values, global_best_position, global_best_value = initialize_particles(num_particles)\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "        particles_position, particles_velocity, personal_best_positions, personal_best_values, global_best_position, global_best_value = update_particles(particles_position, particles_velocity, personal_best_positions, personal_best_values, global_best_position, global_best_value, w1, w2, w3)\n",
        "\n",
        "        if iteration < 5:\n",
        "            print(f\"Epoch {iteration + 1}: Best Position - {global_best_position}, Best Value - {global_best_value}\")\n",
        "\n",
        "    return global_best_position, global_best_value\n",
        "\n",
        "# Parameters\n",
        "num_particles = 20\n",
        "num_iterations = 100\n",
        "w1, w2, w3 = 0.5, 1.5, 1.5  # Adjusted weights for better convergence\n",
        "\n",
        "# Run PSO algorithm\n",
        "best_position, best_value = pso_algorithm(num_particles, num_iterations, w1, w2, w3)\n",
        "\n",
        "print(\"\\nFinal Result:\")\n",
        "print(\"Best Position:\", best_position)\n",
        "print(\"Best Value:\", best_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZvWLHjysj6Q",
        "outputId": "967d439d-85a3-4739-e15f-037a2b7f105b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Best Position - -20.54110586895157, Best Value - -8668.053209823396\n",
            "Epoch 2: Best Position - -85.37427173791414, Best Value - -622274.112577144\n",
            "Epoch 3: Best Position - -1227.012315389412, Best Value - -1847339708.0860126\n",
            "Epoch 4: Best Position - -3026.2617277296276, Best Value - -27715291866.934925\n",
            "Epoch 5: Best Position - -22148.59002485752, Best Value - -10865213210514.76\n",
            "\n",
            "Final Result:\n",
            "Best Position: -2.39916334498223e+73\n",
            "Best Value: -1.3809547640646937e+220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def objective_function(x):\n",
        "    return x**3 + np.sqrt(x) - 1\n",
        "\n",
        "def initialize_particles(num_particles, num_dimensions):\n",
        "    particles = np.random.rand(num_particles, num_dimensions)\n",
        "    velocities = np.random.rand(num_particles, num_dimensions)\n",
        "    fitness_values = np.array([objective_function(p) for p in particles])\n",
        "    return particles, velocities, fitness_values\n",
        "\n",
        "def update_particles(particles, velocities, personal_best_positions, global_best_position, w=1, c1=1, c2=1):\n",
        "    num_particles, num_dimensions = particles.shape\n",
        "\n",
        "    # Update velocity\n",
        "    inertia_term = w * velocities\n",
        "    cognitive_term = c1 * np.random.rand(num_particles, num_dimensions) * (personal_best_positions - particles)\n",
        "    social_term = c2 * np.random.rand(num_particles, num_dimensions) * (global_best_position - particles)\n",
        "    velocities = inertia_term + cognitive_term + social_term\n",
        "\n",
        "    # Update position\n",
        "    particles = particles + velocities\n",
        "\n",
        "    return particles, velocities\n",
        "\n",
        "def update_best_positions(particles, fitness_values, personal_best_positions, global_best_position):\n",
        "    num_particles, num_dimensions = particles.shape\n",
        "\n",
        "    # Update personal best positions\n",
        "    improved_particles = fitness_values < np.array([objective_function(p) for p in personal_best_positions])\n",
        "    for i in range(num_particles):\n",
        "        if improved_particles[i]:\n",
        "            personal_best_positions[i, :] = particles[i, :]\n",
        "\n",
        "    # Update global best position\n",
        "    best_particle = np.argmin(fitness_values)\n",
        "    if fitness_values[best_particle] < objective_function(global_best_position):\n",
        "        global_best_position = particles[best_particle, :]\n",
        "\n",
        "    return personal_best_positions, global_best_position\n",
        "\n",
        "def particle_swarm_optimization(num_particles, num_dimensions, num_iterations, convergence_threshold=1e-6):\n",
        "    # Initialization\n",
        "    particles, velocities, fitness_values = initialize_particles(num_particles, num_dimensions)\n",
        "    personal_best_positions = particles.copy()\n",
        "    global_best_position = particles[np.argmin(fitness_values), :]\n",
        "\n",
        "    # Main loop\n",
        "    for iteration in range(num_iterations):\n",
        "        # Update particles\n",
        "        particles, velocities = update_particles(particles, velocities, personal_best_positions, global_best_position)\n",
        "\n",
        "        # Evaluate fitness\n",
        "        fitness_values = np.array([objective_function(p) for p in particles])\n",
        "\n",
        "        # Update personal and global best positions\n",
        "        personal_best_positions, global_best_position = update_best_positions(\n",
        "            particles, fitness_values, personal_best_positions, global_best_position\n",
        "        )\n",
        "\n",
        "        # Check for convergence\n",
        "        if np.abs(objective_function(global_best_position) - objective_function(personal_best_positions.min(axis=0))) < convergence_threshold:\n",
        "            print(f\"Converged at iteration {iteration + 1}\")\n",
        "            break\n",
        "\n",
        "        # Print the best fitness value at each iteration\n",
        "        print(f\"Iteration {iteration + 1}: Best Fitness = {objective_function(global_best_position)}\")\n",
        "\n",
        "    return global_best_position, objective_function(global_best_position)\n",
        "\n",
        "# Call the PSO function\n",
        "best_position, best_value = particle_swarm_optimization(num_particles=20, num_dimensions=1, num_iterations=100)\n",
        "\n",
        "# Report the results\n",
        "print(f\"Optimal Position: {best_position}\")\n",
        "print(f\"Optimal Value: {best_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5MVymhet1NM",
        "outputId": "49f23194-e008-45c6-9278-ec6f9e95122e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at iteration 1\n",
            "Optimal Position: [0.00032372]\n",
            "Optimal Value: [-0.98200786]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def objective_function(x):\n",
        "    return x**3 + np.sqrt(np.abs(x)) - 1\n",
        "\n",
        "\n",
        "def initialize_particles(num_particles, num_dimensions):\n",
        "    particles = np.random.rand(num_particles, num_dimensions)\n",
        "    velocities = np.random.rand(num_particles, num_dimensions)\n",
        "    fitness_values = np.array([objective_function(p) for p in particles])\n",
        "    return particles, velocities, fitness_values\n",
        "\n",
        "def update_particles(particles, velocities, personal_best_positions, global_best_position, inertia_weight=0.5):\n",
        "    num_particles, num_dimensions = particles.shape\n",
        "\n",
        "    # Update velocity\n",
        "    inertia_term = inertia_weight * velocities\n",
        "    cognitive_term = np.random.rand() * (personal_best_positions - particles)\n",
        "    social_term = np.random.rand() * (global_best_position - particles)\n",
        "    velocities = inertia_term + cognitive_term + social_term\n",
        "\n",
        "    # Update position\n",
        "    particles = particles + velocities\n",
        "\n",
        "    return particles, velocities\n",
        "\n",
        "def update_best_positions(particles, fitness_values, personal_best_positions, global_best_position):\n",
        "    num_particles, num_dimensions = particles.shape\n",
        "\n",
        "    # Update personal best positions\n",
        "    improved_particles = fitness_values < np.array([objective_function(p) for p in fitness_values])\n",
        "    for i in range(num_particles):\n",
        "        if improved_particles[i]:\n",
        "            personal_best_positions[i, :] = particles[i, :]\n",
        "\n",
        "    # Update global best position\n",
        "    best_particle = np.argmin(fitness_values)\n",
        "    if fitness_values[best_particle] < objective_function(global_best_position):\n",
        "        global_best_position = particles[best_particle, :]\n",
        "\n",
        "    return personal_best_positions, global_best_position\n",
        "\n",
        "def particle_swarm_optimization(num_particles, num_dimensions, num_iterations, convergence_threshold=1e-6, inertia_weight=0.5):\n",
        "    # Initialization\n",
        "    particles, velocities, fitness_values = initialize_particles(num_particles, num_dimensions)\n",
        "    personal_best_positions = particles.copy()\n",
        "    global_best_position = particles[np.argmin(fitness_values), :]\n",
        "\n",
        "    # Main loop\n",
        "    for iteration in range(num_iterations):\n",
        "        # Update particles\n",
        "        particles, velocities = update_particles(particles, velocities, personal_best_positions, global_best_position, inertia_weight)\n",
        "\n",
        "        # Evaluate fitness\n",
        "        fitness_values = np.array([objective_function(p) for p in particles])\n",
        "\n",
        "        # Update personal and global best positions\n",
        "        personal_best_positions, global_best_position = update_best_positions(\n",
        "            particles, fitness_values, personal_best_positions, global_best_position\n",
        "        )\n",
        "\n",
        "        # Print the best fitness value and position at each iteration\n",
        "        print(f\"Iteration {iteration + 1}: Best Position = {global_best_position}, Best Fitness = {objective_function(global_best_position)}\")\n",
        "\n",
        "        # Check for convergence\n",
        "        if np.abs(objective_function(global_best_position) - objective_function(personal_best_positions.min(axis=0))) < convergence_threshold:\n",
        "            print(f\"Converged at iteration {iteration + 1}\")\n",
        "            break\n",
        "\n",
        "    return global_best_position, objective_function(global_best_position)\n",
        "\n",
        "# Call the PSO function\n",
        "best_position, best_value = particle_swarm_optimization(num_particles=20, num_dimensions=1, num_iterations=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwJTzsa-4Qtm",
        "outputId": "33fd27a2-66cc-4167-c3e0-5d28b188c63c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Best Position = [0.01087302], Best Fitness = [-0.89572492]\n",
            "Converged at iteration 1\n"
          ]
        }
      ]
    }
  ]
}