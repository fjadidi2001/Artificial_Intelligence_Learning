


# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Specify file path
file_path = '/content/drive/My Drive/telematics_syn.csv'

# Import pandas (assuming you want to use it to read the CSV)
import pandas as pd

# Read the CSV file
df = pd.read_csv(file_path)
print(df.shape)  # Should print (100000, 52)
print(df.head()) # To check the first few rows






# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Specify file path
file_path = '/content/drive/My Drive/telematics_syn.csv'

# Import pandas (assuming you want to use it to read the CSV)
import pandas as pd

# Read the CSV file
df = pd.read_csv(file_path)
print(df.shape)  # Should print (100000, 52)
print(df.columns) # To check the column names

# Encoding categorical columns using one-hot encoding
categorical_cols = ['Marital', 'Insured.sex', 'Car.use', 'Region', 'Territory']
df_level1 = pd.get_dummies(df, columns=categorical_cols)

# Creating the ClaimYN variable
df_level1['ClaimYN'] = df_level1['NB_Claim'].apply(lambda x: 1 if x > 0 else 0)

# Save the preprocessed data to a new file
preprocessed_file_path_level1 = '/content/drive/My Drive/pre_telematics_syn_level1.csv'
df_level1.to_csv(preprocessed_file_path_level1, index=False)
print(df_level1.shape)  # Should print (100000, number of columns after encoding)

from sklearn.preprocessing import StandardScaler, MinMaxScaler

# Copy the DataFrame from Level 1
df_level2 = df_level1.copy()

# Feature columns (excluding response columns)
feature_cols = [col for col in df_level2.columns if col not in ['NB_Claim', 'AMT_Claim', 'ClaimYN']]

# Applying StandardScaler and MinMaxScaler
scaler = StandardScaler()
minmax_scaler = MinMaxScaler()

df_level2[feature_cols] = scaler.fit_transform(df_level2[feature_cols])
df_level2[feature_cols] = minmax_scaler.fit_transform(df_level2[feature_cols])

# Save the preprocessed data to a new file
preprocessed_file_path_level2 = '/content/drive/My Drive/pre_telematics_syn_level2.csv'
df_level2.to_csv(preprocessed_file_path_level2, index=False)
print(df_level2.shape)  # Should print (100000, number of columns after scaling and normalization)

# Copy the DataFrame from Level 2
df_level3 = df_level2.copy()

# Use provided columns for feature engineering
feature_cols_to_sum = ['Annual.pct.driven', 'Annual.miles.drive', 'Pct.drive.rush am']

# Advanced feature engineering steps
df_level3['DrivingIntensity'] = df_level3[feature_cols_to_sum].sum(axis=1)

# Save the fully preprocessed data to a new file
preprocessed_file_path_level3 = '/content/drive/My Drive/pre_telematics_syn_level3.csv'
df_level3.to_csv(preprocessed_file_path_level3, index=False)
print(df_level3.shape)  # Should print (100000, number of columns after feature engineering)

from sklearn.model_selection import train_test_split

# Define the response and feature columns
response_cols = ['NB_Claim', 'AMT_Claim', 'ClaimYN']


def split_data(df):
    feature_cols = [col for col in df.columns if col not in response_cols]

    # Split into 80% train and 20% test
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

    # Further split train into train and validation
    train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)

    return train_df, val_df, test_df, feature_cols

train_df_level1, val_df_level1, test_df_level1, feature_cols_level1 = split_data(df_level1)
train_df_level2, val_df_level2, test_df_level2, feature_cols_level2 = split_data(df_level2)
train_df_level3, val_df_level3, test_df_level3, feature_cols_level3 = split_data(df_level3)

print(train_df_level1.shape, val_df_level1.shape, test_df_level1.shape)
print(train_df_level2.shape, val_df_level2.shape, test_df_level2.shape)
print(train_df_level3.shape, val_df_level3.shape, test_df_level3.shape)





# Install the library
!pip install pytorch-tabnet


# Import required libraries
from pytorch_tabnet.tab_model import TabNetClassifier
import numpy as np
import pandas as pd

def train_tabnet(train_df, val_df, feature_cols, response_col='ClaimYN', epochs=50):
    # Convert boolean columns to integers
    train_df = train_df.applymap(lambda x: int(x) if isinstance(x, bool) else x)
    val_df = val_df.applymap(lambda x: int(x) if isinstance(x, bool) else x)

    # Ensure all data is numeric and convert to numpy arrays
    X_train = train_df[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0).values
    y_train = train_df[response_col].apply(pd.to_numeric, errors='coerce').fillna(0).values
    X_val = val_df[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0).values
    y_val = val_df[response_col].apply(pd.to_numeric, errors='coerce').fillna(0).values

    # Print shapes of the arrays
    print("Shapes of the datasets:")
    print(f"X_train: {X_train.shape}, y_train: {y_train.shape}")
    print(f"X_val: {X_val.shape}, y_val: {y_val.shape}")

    # Verify the types of the arrays
    print("Data types:")
    print(f"X_train type: {type(X_train)}, y_train type: {type(y_train)}")
    print(f"X_val type: {type(X_val)}, y_val type: {type(y_val)}")

    # Print sample data
    print("Sample data:")
    print(f"X_train sample: {X_train[:5]}")
    print(f"y_train sample: {y_train[:5]}")
    print(f"X_val sample: {X_val[:5]}")
    print(f"y_val sample: {y_val[:5]}")

    # Assert that the arrays contain only numeric data
    assert np.issubdtype(X_train.dtype, np.number), "X_train contains non-numeric data"
    assert np.issubdtype(y_train.dtype, np.number), "y_train contains non-numeric data"
    assert np.issubdtype(X_val.dtype, np.number), "X_val contains non-numeric data"
    assert np.issubdtype(y_val.dtype, np.number), "y_val contains non-numeric data"

    clf = TabNetClassifier()

    clf.fit(
        X_train, y_train,
        eval_set=[(X_train, y_train), (X_val, y_val)],
        eval_name=['train', 'val'],
        eval_metric=['accuracy'],
        max_epochs=epochs,
        patience=10,
        batch_size=1024,
        virtual_batch_size=128,
        num_workers=0,
        weights=1,
        drop_last=False
    )

    return clf

# Assuming train_df_level1, val_df_level1, feature_cols_level1, etc., are already defined
clf_level1 = train_tabnet(train_df_level1, val_df_level1, feature_cols_level1)
clf_level2 = train_tabnet(train_df_level2, val_df_level2, feature_cols_level2)
clf_level3 = train_tabnet(train_df_level3, val_df_level3, feature_cols_level3)



# Import required libraries for evaluation
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef, roc_auc_score
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

def evaluate_model(clf, test_df, feature_cols, response_col='ClaimYN'):
    # Ensure all data is numeric
    X_test = test_df[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)
    y_test = test_df[response_col].apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)

    # Calculate predictions
    y_pred = clf.predict(X_test)

    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    mcc = matthews_corrcoef(y_test, y_pred)
    auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])

    print(f'Accuracy: {accuracy}')
    print(f'Recall: {recall}')
    print(f'Precision: {precision}')
    print(f'F1-Score: {f1}')
    print(f'MCC: {mcc}')
    print(f'AUC: {auc}')

    # Plot loss and accuracy if available
    if hasattr(clf, 'history_'):
        history = clf.history_

        plt.figure(figsize=(12, 5))

        plt.subplot(1, 2, 1)
        if 'loss' in history:
            plt.plot(history['loss'], label='train_loss')
        if 'val_loss' in history:
            plt.plot(history['val_loss'], label='val_loss')
        plt.legend()
        plt.title('Loss')

        plt.subplot(1, 2, 2)
        if 'train_accuracy' in history:
            plt.plot(history['train_accuracy'], label='train_accuracy')
        if 'val_accuracy' in history:
            plt.plot(history['val_accuracy'], label='val_accuracy')
        plt.legend()
        plt.title('Accuracy')

        plt.show()
    else:
        print("No training history available for this model.")

print("Evaluation for Level 1:")
evaluate_model(clf_level1, test_df_level1, feature_cols_level1)

print("Evaluation for Level 2:")
evaluate_model(clf_level2, test_df_level2, feature_cols_level2)

print("Evaluation for Level 3:")
evaluate_model(clf_level3, test_df_level3, feature_cols_level3)

