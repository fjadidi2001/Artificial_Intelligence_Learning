





import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

# Load the dataset
df = pd.read_csv('telematics_syn.csv')

# 1. Handling Missing Values
# Check for missing values
missing_values = df.isnull().sum()
print("Missing values in each column:\n", missing_values)

# Impute missing values (using median for numerical and most frequent for categorical)
numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()
categorical_features = df.select_dtypes(exclude=[np.number]).columns.tolist()

# Imputation transformers
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

# Combine transformers into a single preprocessor
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)])

# Apply the preprocessing steps
df_preprocessed = preprocessor.fit_transform(df)

# Convert the result back to a DataFrame
df_preprocessed = pd.DataFrame(df_preprocessed, columns=numerical_features + list(preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)))

# Check the shape of the preprocessed data
print("Shape of preprocessed data:", df_preprocessed.shape)

# Save the preprocessed DataFrame to a new CSV file
df_preprocessed.to_csv('telematics_syn_preprocessed.csv', index=False)

print("Preprocessing completed and saved to 'telematics_syn_preprocessed.csv'")



import pandas as pd
from sklearn.model_selection import train_test_split

# Load the preprocessed dataset
df_preprocessed = pd.read_csv('telematics_syn_preprocessed.csv')

# Split the dataset into train (70%), validation (15%), and test (15%) sets
train_size = 0.7
val_size = 0.15
test_size = 0.15

# Split the data into train and temp sets (train + validation + test)
train_df, temp_df = train_test_split(df_preprocessed, train_size=train_size, random_state=42)

# Split the temp set into validation and test sets
val_df, test_df = train_test_split(temp_df, test_size=test_size/(val_size + test_size), random_state=42)

# Print the sizes of each set
print(f"Training set size: {len(train_df)}")
print(f"Validation set size: {len(val_df)}")
print(f"Test set size: {len(test_df)}")

# Save the splits to CSV files (optional)
train_df.to_csv('telematics_train.csv', index=False)
val_df.to_csv('telematics_val.csv', index=False)
test_df.to_csv('telematics_test.csv', index=False)

print("Dataset splits saved to 'telematics_train.csv', 'telematics_val.csv', and 'telematics_test.csv'")



!pip install pytorch-tabnet



import pandas as pd
import numpy as np
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Load the preprocessed dataset splits
train_df = pd.read_csv('telematics_train.csv')
val_df = pd.read_csv('telematics_val.csv')
test_df = pd.read_csv('telematics_test.csv')

# Separate features and target
X_train = train_df.drop(columns=['NB_Claim'])  # Replace 'NB_Claim' with your target column name
y_train = train_df['NB_Claim'].astype(int)  # Convert target to integer labels

X_val = val_df.drop(columns=['NB_Claim'])
y_val = val_df['NB_Claim'].astype(int)  # Convert target to integer labels

X_test = test_df.drop(columns=['NB_Claim'])
y_test = test_df['NB_Claim'].astype(int)  # Convert target to integer labels

# Initialize the TabNet model
tabnet_model = TabNetClassifier()

# Train the TabNet model
tabnet_model.fit(
    X_train=X_train.values, y_train=y_train.values,
    eval_set=[(X_val.values, y_val.values)],
    eval_name=['val'],
    eval_metric=['accuracy'],
    max_epochs=1000, patience=50,
    batch_size=1024, virtual_batch_size=128,
    num_workers=0,
    weights=1,
    drop_last=False
)

# Evaluate the model on the test set
y_pred = tabnet_model.predict(X_test.values)
test_accuracy = accuracy_score(y_test.values, y_pred)

print(f"Test Accuracy: {test_accuracy}")
print("Confusion Matrix:")
print(confusion_matrix(y_test.values, y_pred))
print("Classification Report:")
print(classification_report(y_test.values, y_pred))

# Save the model
tabnet_model.save_model('tabnet_model')


import pandas as pd
import numpy as np
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt

# Load the preprocessed dataset splits
train_df = pd.read_csv('telematics_train.csv')
val_df = pd.read_csv('telematics_val.csv')
test_df = pd.read_csv('telematics_test.csv')

# Separate features and target
X_train = train_df.drop(columns=['NB_Claim'])  # Replace 'NB_Claim' with your target column name
y_train = train_df['NB_Claim'].astype(int) # Convert target to integer labels

X_val = val_df.drop(columns=['NB_Claim'])
y_val = val_df['NB_Claim'].astype(int) # Convert target to integer labels

X_test = test_df.drop(columns=['NB_Claim'])
y_test = test_df['NB_Claim'].astype(int) # Convert target to integer labels

# Initialize the TabNet model
tabnet_model = TabNetClassifier()

# Train the TabNet model
tabnet_model.fit(
    X_train=X_train.values, y_train=y_train.values,
    eval_set=[(X_train.values, y_train.values), (X_val.values, y_val.values)],
    eval_name=['train', 'val'],
    eval_metric=['accuracy'],
    max_epochs=100, patience=50,
    batch_size=1024, virtual_batch_size=128,
    num_workers=0,
    weights=1,
    drop_last=False
)

# Evaluate the model on the test set
y_pred = tabnet_model.predict(X_test.values)
test_accuracy = accuracy_score(y_test.values, y_pred)

print(f"Test Accuracy: {test_accuracy}")
print("Confusion Matrix:")
print(confusion_matrix(y_test.values, y_pred))
print("Classification Report:")
print(classification_report(y_test.values, y_pred))

# Save the model
tabnet_model.save_model('tabnet_model')

# Extract history for plotting
train_losses = tabnet_model.history['loss']
train_accuracies = tabnet_model.history['train_accuracy']
val_accuracies = tabnet_model.history['val_accuracy']

# Plot accuracy over epochs
plt.figure(figsize=(12, 6))

# Plot training and validation accuracy
plt.subplot(1, 2, 1)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy over Epochs')
plt.legend()

# Plot training loss over epochs
plt.subplot(1, 2, 2)
plt.plot(train_losses, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss over Epochs')
plt.legend()

plt.tight_layout()
plt.show()



import pandas as pd
import numpy as np
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt

# Load the preprocessed dataset splits
train_df = pd.read_csv('telematics_train.csv')
val_df = pd.read_csv('telematics_val.csv')
test_df = pd.read_csv('telematics_test.csv')

# Separate features and target
X_train = train_df.drop(columns=['NB_Claim'])  # Replace 'NB_Claim' with your target column name
y_train = train_df['NB_Claim'].astype(int) # Convert target to integer labels

X_val = val_df.drop(columns=['NB_Claim'])
y_val = val_df['NB_Claim'].astype(int) # Convert target to integer labels

X_test = test_df.drop(columns=['NB_Claim'])
y_test = test_df['NB_Claim'].astype(int) # Convert target to integer labels

# Normalize the data (if needed)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Initialize the TabNet model
tabnet_model = TabNetClassifier()

# Train the TabNet model
tabnet_model.fit(
    X_train=X_train, y_train=y_train,
    eval_set=[(X_train, y_train), (X_val, y_val)],
    eval_name=['train', 'val'],
    eval_metric=['accuracy'],
    max_epochs=100, patience=10,
    batch_size=1024, virtual_batch_size=128,
    num_workers=0,
    weights=1,
    drop_last=False
)

# Evaluate the model on the test set
y_pred = tabnet_model.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)

print(f"Test Accuracy: {test_accuracy}")
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Save the model
tabnet_model.save_model('tabnet_model')

# Extract history for plotting
train_losses = tabnet_model.history['loss']
train_accuracies = tabnet_model.history['train_accuracy']
val_accuracies = tabnet_model.history['val_accuracy']

# Plot accuracy over epochs
plt.figure(figsize=(12, 6))

# Plot training and validation accuracy
plt.subplot(1, 2, 1)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy over Epochs')
plt.legend()

# Plot training loss over epochs
plt.subplot(1, 2, 2)
plt.plot(train_losses, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss over Epochs')
plt.legend()

plt.tight_layout()
plt.show()



import pandas as pd
import numpy as np
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import torch

# Load the preprocessed dataset splits
train_df = pd.read_csv('telematics_train.csv')
val_df = pd.read_csv('telematics_val.csv')
test_df = pd.read_csv('telematics_test.csv')

# Separate features and target
X_train = train_df.drop(columns=['NB_Claim'])  # Replace 'NB_Claim' with your target column name
y_train = train_df['NB_Claim'].astype(int) # Convert target to integer labels

X_val = val_df.drop(columns=['NB_Claim'])
y_val = val_df['NB_Claim'].astype(int) # Convert target to integer labels

X_test = test_df.drop(columns=['NB_Claim'])
y_test = test_df['NB_Claim'].astype(int) # Convert target to integer labels

# Normalize the data
scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Initialize the TabNet model with regularization and dropout
tabnet_model = TabNetClassifier(
    optimizer_params=dict(lr=2e-2),
    scheduler_params={"step_size":10, "gamma":0.9},
    scheduler_fn=torch.optim.lr_scheduler.StepLR,
    mask_type='entmax',  # "sparsemax"
    n_d=16, n_a=16, n_steps=5,
    gamma=1.5, n_independent=2, n_shared=2,
    lambda_sparse=1e-3,  # Add sparse regularization
    momentum=0.3,
    clip_value=2.,  # Gradient clipping
    verbose=1
)

# Train the TabNet model with additional dropout and L2 regularization
tabnet_model.fit(
    X_train=X_train, y_train=y_train,
    eval_set=[(X_train, y_train), (X_val, y_val)],
    eval_name=['train', 'val'],
    eval_metric=['accuracy'],
    max_epochs=100, patience=10,
    batch_size=1024, virtual_batch_size=128,
    num_workers=0,
    drop_last=False
)

# Evaluate the model on the test set
y_pred = tabnet_model.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)

print(f"Test Accuracy: {test_accuracy}")
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Save the model
tabnet_model.save_model('tabnet_model')

# Extract history for plotting
train_losses = tabnet_model.history['loss']
train_accuracies = tabnet_model.history['train_accuracy']
val_accuracies = tabnet_model.history['val_accuracy']

# Plot accuracy over epochs
plt.figure(figsize=(12, 6))

# Plot training and validation accuracy
plt.subplot(1, 2, 1)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy over Epochs')
plt.legend()

# Plot training loss over epochs
plt.subplot(1, 2, 2)
plt.plot(train_losses, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

