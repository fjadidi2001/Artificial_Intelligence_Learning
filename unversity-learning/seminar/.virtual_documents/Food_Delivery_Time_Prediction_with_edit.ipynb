











import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px


df = pd.read_csv("deliverytime.txt")
df.head()


df.info()


df.isnull().sum()











# Set the earth's radius (in kilometers)
R = 6371

# Convert degrees to radians
def deg_to_rad(degrees):
    return degrees * (np.pi/180)

# Function to calculate the distance between two points using the haversine formula
def distcalculate(lat1, lon1, lat2, lon2):
    d_lat = deg_to_rad(lat2-lat1)
    d_lon = deg_to_rad(lon2-lon1)
    a = np.sin(d_lat/2)**2 + np.cos(deg_to_rad(lat1)) * np.cos(deg_to_rad(lat2)) * np.sin(d_lon/2)**2
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))
    return R * c


# Calculate the distance between each pair of points
df['distance'] = np.nan

for i in range(len(df)):
    df.loc[i,'distance'] = distcalculate(df.loc[i, 'Restaurant_latitude'],
                                        df.loc[i, 'Restaurant_longitude'],
                                        df.loc[i, 'Delivery_location_latitude'],
                                        df.loc[i, 'Delivery_location_longitude'])





df.head()








figure = px.scatter(data_frame = df,
                   x = 'distance',
                   y = 'Time_taken(min)',
                   size = 'Time_taken(min)',
                   trendline = 'ols',
                   title = "Relationship Between Distance and Time Taken")

figure.show()








figure = px.scatter(data_frame = df,
                   x = 'Delivery_person_Age',
                   y = 'Time_taken(min)',
                   size = 'Time_taken(min)',
                   color = 'distance',
                   trendline = 'ols',
                   title = 'Relation between Age and time')

figure.show()








figure = px.scatter(data_frame = df,
                    x='Delivery_person_Ratings',
                    y = 'Time_taken(min)',
                    size = 'Time_taken(min)',
                    color = 'distance',
                    trendline = 'ols',
                    title = 'Relation between the Ratings and time taken')

figure.show()








figure = px.box(df,
               x = 'Type_of_vehicle',
               y = 'Time_taken(min)',
               color = 'Type_of_order')
figure.show()














#splitting data
from sklearn.model_selection import train_test_split
# important col
x = np.array(df[["Delivery_person_Age",
                  "Delivery_person_Ratings",
                  "distance"]])
# label
y = np.array(df[["Time_taken(min)"]])

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.10,random_state = 42)


# creating the LSTM neural network model
from keras.models import Sequential
from keras.layers import Dense, LSTM
model = Sequential()
model.add(LSTM(128,return_sequences = True,input_shape = (x_train.shape[1],1)))
model.add(LSTM(64,return_sequences = False))
model.add(Dense(25))
model.add(Dense(1))
model.summary()


# training the model
model.compile(optimizer = 'adam',loss = 'mean_squared_error')
model.fit(x_train,y_train,batch_size = 1, epochs = 10)





print("Fodd Delivery Time Prediction")
a = int(input("Age of Delivery Partner: "))
b = float(input("Ratings of Previous Delivery: "))
c = int(input("Total Distance: "))

features = np.array([[a,b,c]])
print("Predicted delivery Time in Minutes : ",model.predict(features))


from sklearn.metrics import mean_squared_error, r2_score

# Evaluate the model on the test set
y_pred = model.predict(x_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse:.2f}')
print(f'R-squared: {r2:.2f}')



from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Random Forest Regressor
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(x_train, y_train)
rf_pred = rf_model.predict(x_test)
rf_mse = mean_squared_error(y_test, rf_pred)
rf_r2 = r2_score(y_test, rf_pred)
print(f'Random Forest MSE: {rf_mse:.2f}')
print(f'Random Forest R-squared: {rf_r2:.2f}')

# XGBoost Regressor
xgb_model = XGBRegressor(random_state=42)
xgb_model.fit(x_train, y_train)
xgb_pred = xgb_model.predict(x_test)
xgb_mse = mean_squared_error(y_test, xgb_pred)
xgb_r2 = r2_score(y_test, xgb_pred)
print(f'XGBoost MSE: {xgb_mse:.2f}')
print(f'XGBoost R-squared: {xgb_r2:.2f}')









import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten
from tensorflow.keras.callbacks import EarlyStopping

# Load the data
df = pd.read_csv("deliverytime.txt")

# Normalize the features
scaler = MinMaxScaler()
df[["delivery_person_age", "delivery_person_ratings", "distance"]] = scaler.fit_transform(df[["delivery_person_age", "delivery_person_ratings", "distance"]])

# Split the data
x = df[["Delivery_person_Age", "Delivery_person_Ratings", "distance"]].values
y = df["Time_taken(min)"].values
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)

# Reshape the input to be 3D [samples, timesteps, features]
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

# Create the model
model = Sequential()
model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x_train.shape[1], 1)))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Define early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5)

# Train the model
model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])

# Prediction
a = int(input("Age of Delivery Partner: "))
b = float(input("Ratings of Previous Delivery: "))
c = int(input("Total Distance: "))
features = np.array([[a, b, c]])
features = scaler.transform(features)  # Normalize the input features
features = np.reshape(features, (features.shape[0], features.shape[1], 1))
prediction = model.predict(features)
print("Predicted delivery Time in Minutes : ", prediction[0][0])  # Access the first element of the prediction array


import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten
from tensorflow.keras.callbacks import EarlyStopping

# Load the data
df = pd.read_csv("deliverytime.txt", delimiter='\t')  # Assuming the file is tab-separated

# Normalize the features
scaler = MinMaxScaler()
df[["Delivery_person_Age", "Delivery_person_Ratings", "distance"]] = scaler.fit_transform(df[["Delivery_person_Age", "Delivery_person_Ratings", "distance"]])

# Split the data
x = df[["Delivery_person_Age", "Delivery_person_Ratings", "distance"]].values
y = df["Time_taken(min)"].values
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)

# Reshape the input to be 3D [samples, timesteps, features]
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

# Create the model
model = Sequential()
model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x_train.shape[1], 1)))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Define early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5)

# Train the model
model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])

# Prediction
a = int(input("Age of Delivery Partner: "))
b = float(input("Ratings of Previous Delivery: "))
c = int(input("Total Distance: "))
features = np.array([[a, b, c]])
features = scaler.transform(features)  # Normalize the input features
features = np.reshape(features, (features.shape[0], features.shape[1], 1))
prediction = model.predict(features)
print("Predicted delivery Time in Minutes : ", prediction[0][0])  # Access the first element of the prediction array


df = pd.read_csv("deliverytime.txt", delimiter='\t', encoding='utf-8')


print(df.columns)


from math import radians, cos, sin, asin, sqrt

def haversine(lon1, lat1, lon2, lat2):
    """
    Calculate the great circle distance between two points
    on the earth (specified in decimal degrees)
    """
    # Convert decimal degrees to radians
    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])

    # Haversine formula
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * asin(sqrt(a))

    # Radius of earth in kilometers is 6371
    km = 6371* c
    return km

# Calculate the distance between the restaurant and delivery location
df['distance'] = df.apply(lambda row: haversine(row['Restaurant_longitude'], row['Restaurant_latitude'], row['Delivery_location_longitude'], row['Delivery_location_latitude']), axis=1)


print(df.columns)


if df.empty:
    print("DataFrame is empty.")
else:
    print("DataFrame is not empty.")


# Clean the column names by stripping leading/trailing whitespace
df.columns = df.columns.str.strip()

# Check if the cleaned column names match the expected names
expected_columns = ['ID', 'Delivery_person_ID', 'Delivery_person_Age',
                    'Delivery_person_Ratings', 'Restaurant_latitude',
                    'Restaurant_longitude', 'Delivery_location_latitude',
                    'Delivery_location_longitude', 'Type_of_order', 'Type_of_vehicle',
                    'Time_taken(min)']

if set(df.columns) == set(expected_columns):
    print("Column names match.")
else:
    print("Column names do not match. Expected:", expected_columns)
    print("Actual:", df.columns)


df.columns = df.columns.str.replace('\xa0', ' ')  # Replace non-breaking spaces with regular spaces


print(df.columns)


import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten
from tensorflow.keras.callbacks import EarlyStopping
from math import radians, cos, sin, asin, sqrt





# Calculate the distance between the restaurant and delivery location
df['distance'] = df.apply(lambda row: haversine(row['Restaurant_longitude'], row['Restaurant_latitude'], row['Delivery_location_longitude'], row['Delivery_location_latitude']), axis=1)

# Normalize the features
scaler = MinMaxScaler()
df[["Delivery_person_Age", "Delivery_person_Ratings", "distance"]] = scaler.fit_transform(df[["Delivery_person_Age", "Delivery_person_Ratings", "distance"]])

# Split the data
x = df[["Delivery_person_Age", "Delivery_person_Ratings", "distance"]].values
y = df["Time_taken(min)"].values
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)

# Reshape the input to be 3D [samples, timesteps, features]
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

# Create the model
model = Sequential()
model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x_train.shape[1], 1)))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Define early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5)

# Train the model
model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])

# Prediction
a = int(input("Age of Delivery Partner: "))
b = float(input("Ratings of Previous Delivery: "))
c = int(input("Total Distance: "))
features = np.array([[a, b, c]])
features = scaler.transform(features)  # Normalize the input features
features = np.reshape(features, (features.shape[0], features.shape[1], 1))
prediction = model.predict(features)
print("Predicted delivery Time in Minutes : ", prediction[0][0])  # Access the first element of the prediction array
