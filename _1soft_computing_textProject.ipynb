{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8xUfCKuP/AcJhD/rYkL45",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Artificial_Intelligence_Learning/blob/master/_1soft_computing_textProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NYiWpqOpeAmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdbd3653-d915-49bb-f7b4-465b56cde21e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "[[255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " ...\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]]\n",
            "\n",
            "Bipolar Encoded Dataset:\n",
            "[[-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " ...\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Load the dataset from a text file\n",
        "def load_dataset(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    dataset = [list(map(int, line.split())) for line in lines]\n",
        "    '''\n",
        "    This line of code creates a dataset by iterating through each line in the variable `lines`,\n",
        "    splitting each line into a list of strings,\n",
        "    converting each string to an integer using the `map` function,\n",
        "    and then converting the resulting map object into a list.\n",
        "    The final dataset is a list of lists, with each inner list containing integers parsed from the original lines.\n",
        "    '''\n",
        "    return np.array(dataset)\n",
        "# Provide the correct path to your text file\n",
        "file_path = '/content/fars.txt'\n",
        "original_dataset = load_dataset(file_path)\n",
        "\n",
        "# Step 2: Convert dataset to bipolar encoding based on the specified condition\n",
        "def convert_to_bipolar_with_condition(dataset):\n",
        "    return np.where(dataset > 128, -1, 1)\n",
        "\n",
        "bipolar_dataset = convert_to_bipolar_with_condition(original_dataset)\n",
        "\n",
        "# Print original and bipolar datasets for verification\n",
        "print(\"Original Dataset:\")\n",
        "print(original_dataset)\n",
        "\n",
        "print(\"\\nBipolar Encoded Dataset:\")\n",
        "print(bipolar_dataset)\n",
        "# bipolar_dataset.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Reshape each sequence into a matrix\n",
        "num_fonts = 7\n",
        "sequence_length = 17\n",
        "\n",
        "# Reshape each sequence into a 2D matrix\n",
        "\n",
        "'''\n",
        "This line of code reshapes the original dataset into a new matrix dataset.\n",
        "The \"-1\" indicates that the first dimension of the new dataset will be inferred based on the total size of the original dataset\n",
        "and the specified number of fonts and sequence length. This reshaping is useful for preparing the data for input into a neural network,\n",
        "where the input shape may need to be specified in a certain way.\n",
        "'''\n",
        "matrix_dataset = original_dataset.reshape(-1, num_fonts, sequence_length)\n",
        "\n",
        "\n",
        "# Print the original and matrix datasets for verification\n",
        "print(\"Original Dataset:\")\n",
        "print(original_dataset)\n",
        "\n",
        "print(\"\\nMatrix Dataset:\")\n",
        "print(matrix_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACVO6l9PY1cO",
        "outputId": "e33f6511-8fa5-4903-f09c-23956eb062ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "[[255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " ...\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]]\n",
            "\n",
            "Matrix Dataset:\n",
            "[[[255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  ...\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]]\n",
            "\n",
            " [[255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  ...\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]]\n",
            "\n",
            " [[255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  ...\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  ...\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]]\n",
            "\n",
            " [[255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  ...\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]]\n",
            "\n",
            " [[255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  ...\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Convert dataset to bipolar encoding based on the specified condition\n",
        "def convert_to_bipolar_with_condition(dataset):\n",
        "    return np.where(dataset > 128, -1, 1)\n",
        "\n",
        "bipolar_dataset = convert_to_bipolar_with_condition(original_dataset)\n",
        "\n",
        "# Step 3: Reshape each sequence into a matrix\n",
        "num_fonts = 7\n",
        "sequence_length = 17\n",
        "\n",
        "# Reshape each sequence into a 2D matrix\n",
        "matrix_dataset = bipolar_dataset.reshape(-1, num_fonts, sequence_length)\n",
        "\n",
        "# Print the original, bipolar, and matrix datasets for verification\n",
        "print(\"Original Dataset:\")\n",
        "print(original_dataset)\n",
        "\n",
        "print(\"\\nBipolar Encoded Dataset:\")\n",
        "print(bipolar_dataset)\n",
        "\n",
        "print(\"\\nMatrix Dataset:\")\n",
        "print(matrix_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6QEadIxZDeI",
        "outputId": "731272f4-fd73-4157-f6c4-4d16440b120c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "[[255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " ...\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]]\n",
            "\n",
            "Bipolar Encoded Dataset:\n",
            "[[-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " ...\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            "Matrix Dataset:\n",
            "[[[-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " [[-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " [[-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " [[-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " [[-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_characters = 17\n",
        "num_fonts = 7\n",
        "input_size = 95 * 95\n",
        "\n",
        "# Reshape each character with different fonts into a matrix\n",
        "character_matrices = bipolar_dataset.reshape(num_characters, num_fonts, 95, 95)\n",
        "# Flatten each matrix to create input vectors\n",
        "input_vectors = character_matrices.reshape(num_characters * num_fonts, -1)\n",
        "# Step 2: Build a simple perceptron network with random weights\n",
        "num_weights = input_size\n",
        "weights = np.random.randn(num_weights, 1)\n",
        "\n",
        "# Step 3: Define activation function (sigmoid) and forward pass\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def forward_pass(data, weights):\n",
        "    return sigmoid(np.dot(data, weights))\n",
        "\n",
        "# Step 4: Train the perceptron network for 10 epochs\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for char_font_idx in range(num_characters * num_fonts):\n",
        "        # Select the input vector for the current character and font\n",
        "        input_vector = input_vectors[char_font_idx, :]\n",
        "\n",
        "        # Forward pass\n",
        "        output = forward_pass(input_vector, weights)\n",
        "\n",
        "        # Convert output to bipolar (-1 or 1)\n",
        "        output_bipolar = np.where(output > 0.5, 1, -1)\n",
        "\n",
        "        # Update weights (dummy update, not based on any real learning algorithm)\n",
        "        weights += np.random.randn(num_weights, 1) * 0.01  # Adjust the learning rate as needed\n",
        "\n",
        "# Step 5: Make predictions for each character and font\n",
        "predictions = np.zeros((num_characters, num_fonts))\n",
        "\n",
        "for char_idx in range(num_characters):\n",
        "    for font_idx in range(num_fonts):\n",
        "        input_vector = input_vectors[char_idx * num_fonts + font_idx, :]\n",
        "        predictions[char_idx, font_idx] = np.where(forward_pass(input_vector, weights) > 0.5, 1, -1)\n",
        "\n",
        "# Print predictions for verification\n",
        "print(\"Predictions:\")\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvtL_HwqZZ37",
        "outputId": "a144b187-4f95-4632-940b-107e8608a11f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:\n",
            "[[-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1.  1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1. -1.  1. -1. -1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add bias term to input vectors\n",
        "input_vectors_with_bias = np.c_[input_vectors, np.ones((num_characters * num_fonts, 1))]  # Adding a column of ones for bias\n",
        "\n",
        "# Create target labels (true if the character is present in any font)\n",
        "target_labels = np.zeros((num_characters, num_fonts))\n",
        "for char_idx in range(num_characters):\n",
        "    random_font_idx = np.random.randint(num_fonts)  # Randomly select a font for each character\n",
        "    target_labels[char_idx, random_font_idx] = 1\n",
        "target_labels = np.where(target_labels == 0, -1, 1)\n",
        "print(\"\\nTarget Labels:\")\n",
        "print(target_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC101hd0Z-td",
        "outputId": "3c3466ec-4528-4317-db64-26ac07df387f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target Labels:\n",
            "[[-1 -1  1 -1 -1 -1 -1]\n",
            " [-1 -1 -1  1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1  1]\n",
            " [-1 -1 -1 -1  1 -1 -1]\n",
            " [ 1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1  1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1  1 -1]\n",
            " [ 1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1  1]\n",
            " [ 1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1  1 -1 -1 -1]\n",
            " [-1 -1 -1 -1  1 -1 -1]\n",
            " [-1  1 -1 -1 -1 -1 -1]\n",
            " [-1 -1  1 -1 -1 -1 -1]\n",
            " [ 1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1  1 -1]\n",
            " [-1 -1  1 -1 -1 -1 -1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "file_path = '/content/fars.txt'  # Replace with the correct path to your text file\n",
        "original_dataset = np.loadtxt(file_path)\n",
        "\n",
        "\n",
        "# Add bias term to input vectors\n",
        "input_vectors_with_bias = np.c_[input_vectors, np.ones((num_characters * num_fonts, 1))]  # Adding a column of ones for bias\n",
        "\n",
        "# Create target labels (true if the character is present in any font)\n",
        "target_labels = np.zeros((num_characters, num_fonts), dtype=int)\n",
        "for char_idx in range(num_characters):\n",
        "    random_font_idx = np.random.randint(num_fonts)  # Randomly select a font for each character\n",
        "    target_labels[char_idx, random_font_idx] = 1\n",
        "\n",
        "# Step 2: Build a simple perceptron network with random weights\n",
        "num_weights = input_size + 1  # Additional weight for bias\n",
        "weights = np.random.randn(num_weights, 1)\n",
        "\n",
        "# Step 3: Define activation function (sigmoid) and forward pass\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def forward_pass(data, weights):\n",
        "    return sigmoid(np.dot(data, weights))\n",
        "\n",
        "# Step 4: Train network for 10 epochs\n",
        "epochs = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for char_font_idx in range(num_characters * num_fonts):\n",
        "        # Select the input vector for the current character and font\n",
        "        input_vector = input_vectors_with_bias[char_font_idx, :].reshape(1, -1)\n",
        "\n",
        "        # Select the target label for the current character and font\n",
        "        target_label = target_labels[char_font_idx // num_fonts, char_font_idx % num_fonts]\n",
        "\n",
        "        # Forward pass\n",
        "        output = forward_pass(input_vector, weights)\n",
        "\n",
        "        # Update weights using perceptron learning rule\n",
        "        weights += learning_rate * (target_label - output) * input_vector.T\n",
        "\n",
        "# Step 5: Make predictions for each character and font\n",
        "predictions = np.zeros((num_characters, num_fonts), dtype=int)\n",
        "\n",
        "for char_idx in range(num_characters):\n",
        "    for font_idx in range(num_fonts):\n",
        "        input_vector = input_vectors_with_bias[char_idx * num_fonts + font_idx, :].reshape(1, -1)\n",
        "        predictions[char_idx, font_idx] = int(forward_pass(input_vector, weights) > 0.5)\n",
        "\n",
        "def convert_to_bipolar_with_condition(predictions):\n",
        "  return np.where(predictions==0,-1,1)\n",
        "predict1=convert_to_bipolar_with_condition(predictions)\n",
        "\n",
        "\n",
        "def convert_to_bipolar_with_condition(target_labels):\n",
        "  return np.where(target_labels==0,-1,1)\n",
        "target1=convert_to_bipolar_with_condition(target_labels)\n",
        "\n",
        "# Print predictions and target labels for verification\n",
        "print(\"Predictions:\")\n",
        "print(predict1)\n",
        "print(\"\\nTarget Labels:\")\n",
        "print(target1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.sum(predictions == target_labels) / (num_characters * num_fonts)\n",
        "print(\"\\nAccuracy for train set:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT0OQYU_a8DA",
        "outputId": "68fe16c9-ee1c-4e76-f55b-c3ec6bdafc60"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:\n",
            "[[-1 -1 -1  1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1  1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1  1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1  1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1  1 -1 -1]]\n",
            "\n",
            "Target Labels:\n",
            "[[-1 -1 -1  1 -1 -1 -1]\n",
            " [-1 -1  1 -1 -1 -1 -1]\n",
            " [-1  1 -1 -1 -1 -1 -1]\n",
            " [ 1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1  1 -1 -1 -1 -1]\n",
            " [-1 -1  1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1  1]\n",
            " [ 1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1  1 -1]\n",
            " [ 1 -1 -1 -1 -1 -1 -1]\n",
            " [-1  1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1  1]\n",
            " [-1 -1 -1 -1 -1  1 -1]\n",
            " [-1 -1 -1  1 -1 -1 -1]\n",
            " [-1 -1 -1  1 -1 -1 -1]\n",
            " [-1  1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1  1 -1 -1]]\n",
            "\n",
            "Accuracy for train set: 0.8991596638655462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "test_size = 0.2\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_vectors_with_bias, target_labels.flatten(), test_size=test_size, random_state=42)\n",
        "\n",
        "# Step 2: Build a simple perceptron network with random weights\n",
        "num_weights = input_size + 1\n",
        "weights = np.random.randn(num_weights, 1)\n",
        "\n",
        "# Step 3: Define activation function (sigmoid) and forward pass\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def forward_pass(data, weights):\n",
        "    return sigmoid(np.dot(data, weights))\n",
        "\n",
        "# Step 4: Train the perceptron network for 10 epochs\n",
        "epochs = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for idx in range(len(X_train)):\n",
        "        # Select the input vector for the current sample\n",
        "        input_vector = X_train[idx, :].reshape(1, -1)\n",
        "        target_label = y_train[idx]\n",
        "\n",
        "        # Forward pass\n",
        "        output = forward_pass(input_vector, weights)\n",
        "\n",
        "        # Update weights using perceptron learning rule\n",
        "        weights += learning_rate * (target_label - output) * input_vector.T\n",
        "\n",
        "# Step 5: Make predictions on the test set\n",
        "predictions = np.zeros_like(y_test)\n",
        "\n",
        "for idx in range(len(X_test)):\n",
        "    input_vector = X_test[idx, :].reshape(1, -1)\n",
        "    predictions[idx] = int(forward_pass(input_vector, weights) > 0.5)\n",
        "\n",
        "def convert_to_bipolar_with_condition(predictions):\n",
        "  return np.where(predictions==0,-1,1)\n",
        "predict1=convert_to_bipolar_with_condition(predictions)\n",
        "# print(\"Predictions:\")\n",
        "# print(predict1)\n",
        "def convert_to_bipolar_with_condition(target_labels):\n",
        "  return np.where(target_labels==0,-1,1)\n",
        "target1=convert_to_bipolar_with_condition(target_labels)\n",
        "# print(\"\\nTarget Labels:\")\n",
        "# print(target1)\n",
        "\n",
        "\n",
        "#  accuracy on the test set\n",
        "accuracy = np.sum(predictions == y_test) / len(y_test)\n",
        "print(\"\\nAccuracy for Test Set:\", accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu3KgjWh8i9R",
        "outputId": "f3661989-f41f-4205-d1a3-c2a54f82de40"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy for Test Set: 95.83333333333334\n"
          ]
        }
      ]
    }
  ]
}