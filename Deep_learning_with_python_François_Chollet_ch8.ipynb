{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmK493yz84EGB66annoXAI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Artificial_Intelligence_Learning/blob/master/Deep_learning_with_python_Fran%C3%A7ois_Chollet_ch8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OCR** stands for \"Optical Character Recognition.\" It is a technology that recognizes text within a digital image. It is commonly used to recognize text in scanned documents and images. OCR software can be used to convert a physical paper document, or an image into an accessible electronic version with text."
      ],
      "metadata": {
        "id": "3o7zOHAAuUDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.1 introduction to convnets(convolutional neural networks)"
      ],
      "metadata": {
        "id": "bqqSb8YmxV50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "simple convnet example that classifies MNIST digits\n",
        "- build the model using the Functional API\n",
        "- stack of Conv2D and MaxPooling2D layers"
      ],
      "metadata": {
        "id": "C0_iOYiUxlFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x3Tk9yizyH1",
        "outputId": "daa5da46-2307-490e-9de3-35c8c695de19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "TTYLJ7hGy2TS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet is a simple example of building a convolutional neural network (CNN) using TensorFlow's Keras API for image classification tasks. Here's a breakdown of what each line does:\n",
        "\n",
        "1. `from tensorflow import keras`: Imports the Keras module from TensorFlow.\n",
        "2. `from tensorflow.keras import layers`: Imports the layers module from Keras.\n",
        "3. `inputs = keras.Input(shape=(28, 28, 1))`: Defines the input layer with a shape of (28, 28, 1), which is commonly used for processing grayscale images of size 28x28 pixels.\n",
        "Importantly, a convnet takes as input tensors of shape (image_height, image_width, image_channels), not including the batch dimension. In this case, we’ll configure the convnet to process inputs of size (28, 28, 1), which is the format of MNIST images.\n",
        "4. `x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)`: Adds a 2D convolutional layer with 32 filters, a kernel size of 3x3, and ReLU activation function after the input layer.\n",
        "5. `x = layers.MaxPooling2D(pool_size=2)(x)`: Adds a max-pooling layer with a pool size of 2x2 after the convolutional layer to downsample the feature maps.\n",
        "6. `x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)`: Adds another 2D convolutional layer with 64 filters and a kernel size of 3x3 after the max-pooling layer.\n",
        "7. `x = layers.MaxPooling2D(pool_size=2)(x)`: Adds another max-pooling layer after the second convolutional layer.\n",
        "8. `x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)`: Adds a third 2D convolutional layer with 128 filters and a kernel size of 3x3.\n",
        "9. `x = layers.Flatten()(x)`: Flattens the output from the convolutional layers into a 1D array to feed into a dense layer.\n",
        "10. `outputs = layers.Dense(10, activation=\"softmax\")(x)`: Adds a dense layer with 10 units (for 10 classes in this case) and a softmax activation function to generate class probabilities.\n",
        "11. `model = keras.Model(inputs=inputs, outputs=outputs)`: Creates a Keras Model by specifying the input and output layers of the model.\n",
        "\n",
        "This code defines a CNN model architecture for image classification tasks, specifically designed for processing grayscale images of size 28x28 pixels.\n"
      ],
      "metadata": {
        "id": "rUTgYIJkzFzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xPEay5fzWgW",
        "outputId": "cc3e9109-8406-4095-90fa-4ba91679524d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                11530     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104202 (407.04 KB)\n",
            "Trainable params: 104202 (407.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You can see that the output of every Conv2D and MaxPooling2D layer is a rank-3 tensor of shape (height, width, channels). The width and height dimensions tend to shrink as you go deeper in the model. The number of channels is controlled by the first argument passed to the Conv2D layers (32, 64, or 128).\n",
        "After the last Conv2D layer, we end up with an output of shape (3, 3, 128) —a 3 × 3 feature map of 128 channels.\n",
        "<br><br>\n",
        "The next step is to feed this output into a densely connected classifier like those you're already familiar with: a stack of Dense layers. These classifiers process vectors, which are 1D, whereas the current output is a rank-3 tensor. To bridge the gap, we flatten the 3D outputs to ID with a Flatten layer before adding the Dense layers.\n",
        "Finally, we do 10-way classification, so our last layer has 10 outputs and a softmax activation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L0TwtSkK1zAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "loss=\"sparse_categorical_crossentropy\",\n",
        "metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C8aoA4t22Aw",
        "outputId": "86001060-651e-419e-f6df-9624e7b3ea0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 54s 57ms/step - loss: 0.1652 - accuracy: 0.9486\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 53s 57ms/step - loss: 0.0449 - accuracy: 0.9862\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 53s 57ms/step - loss: 0.0304 - accuracy: 0.9906\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 54s 57ms/step - loss: 0.0240 - accuracy: 0.9928\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 53s 57ms/step - loss: 0.0178 - accuracy: 0.9949\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7adc87092470>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet demonstrates the process of preparing the MNIST dataset for training a neural network model using TensorFlow's Keras API. Here is a breakdown of each line:\n",
        "\n",
        "1. `from tensorflow.keras.datasets import mnist`: Imports the MNIST dataset from Keras, which is a popular dataset of handwritten digits for image classification tasks.\n",
        "2. `(train_images, train_labels), (test_images, test_labels) = mnist.load_data()`: Loads the MNIST dataset, splitting it into training and testing sets with images and corresponding labels.\n",
        "3. `train_images = train_images.reshape((60000, 28, 28, 1))`: Reshapes the training images array to have a shape of (60000, 28, 28, 1) to match the input shape expected by the neural network model.\n",
        "4. `train_images = train_images.astype(\"float32\") / 255`: Converts the training images to float32 data type and normalizes the pixel values to be between 0 and 1 by dividing by 255.\n",
        "5. `test_images = test_images.reshape((10000, 28, 28, 1))`: Reshapes the testing images array to have a shape of (10000, 28, 28, 1) to match the input shape expected by the neural network model.\n",
        "6. `test_images = test_images.astype(\"float32\") / 255`: Converts the testing images to float32 data type and normalizes the pixel values to be between 0 and 1 by dividing by 255.\n",
        "7. `model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])`: Compiles the model with the RMSprop optimizer, sparse categorical crossentropy loss function (suitable for integer-encoded labels), and accuracy as the metric to monitor during training.\n",
        "8. `model.fit(train_images, train_labels, epochs=5, batch_size=64)`: Trains the model using the training images and labels for 5 epochs with a batch size of 64 samples per gradient update.\n",
        "\n",
        "Overall, this code snippet sets up the MNIST dataset, preprocesses the data for training, compiles the model with appropriate settings, and trains the model on the training data for a specified number of epochs.\n"
      ],
      "metadata": {
        "id": "yVIzc-2X_6jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIh_WuCQ_1Q3",
        "outputId": "6b89696a-1223-4d35-82a8-fc80a9534946"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0192 - accuracy: 0.9934\n",
            "Test accuracy: 0.993\n"
          ]
        }
      ]
    }
  ]
}