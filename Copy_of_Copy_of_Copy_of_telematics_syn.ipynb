{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpw/2zSKKPx3wIpFcWnz4d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Artificial_Intelligence_Learning/blob/master/Copy_of_Copy_of_Copy_of_telematics_syn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('telematics_syn.csv')\n",
        "\n",
        "# 1. Handling Missing Values\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values in each column:\\n\", missing_values)\n",
        "\n",
        "# Impute missing values (using median for numerical and most frequent for categorical)\n",
        "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "# Imputation transformers\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# Combine transformers into a single preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Apply the preprocessing steps\n",
        "df_preprocessed = preprocessor.fit_transform(df)\n",
        "\n",
        "# Convert the result back to a DataFrame\n",
        "df_preprocessed = pd.DataFrame(df_preprocessed, columns=numerical_features + list(preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)))\n",
        "\n",
        "# Check the shape of the preprocessed data\n",
        "print(\"Shape of preprocessed data:\", df_preprocessed.shape)\n",
        "\n",
        "# Save the preprocessed DataFrame to a new CSV file\n",
        "df_preprocessed.to_csv('telematics_syn_preprocessed.csv', index=False)\n",
        "\n",
        "print(\"Preprocessing completed and saved to 'telematics_syn_preprocessed.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMyAAm9K5ynk",
        "outputId": "0f521e7d-8506-4b66-83b8-00e878f1ee70"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            " Duration                  0\n",
            "Insured.age               0\n",
            "Insured.sex               0\n",
            "Car.age                   0\n",
            "Marital                   0\n",
            "Car.use                   0\n",
            "Credit.score              0\n",
            "Region                    0\n",
            "Annual.miles.drive        0\n",
            "Years.noclaims            0\n",
            "Territory                 0\n",
            "Annual.pct.driven         0\n",
            "Total.miles.driven        0\n",
            "Pct.drive.mon             0\n",
            "Pct.drive.tue             0\n",
            "Pct.drive.wed             0\n",
            "Pct.drive.thr             0\n",
            "Pct.drive.fri             0\n",
            "Pct.drive.sat             0\n",
            "Pct.drive.sun             0\n",
            "Pct.drive.2hrs            0\n",
            "Pct.drive.3hrs            0\n",
            "Pct.drive.4hrs            0\n",
            "Pct.drive.wkday           0\n",
            "Pct.drive.wkend           0\n",
            "Pct.drive.rush am         0\n",
            "Pct.drive.rush pm         0\n",
            "Avgdays.week              0\n",
            "Accel.06miles             0\n",
            "Accel.08miles             0\n",
            "Accel.09miles             0\n",
            "Accel.11miles             0\n",
            "Accel.12miles             0\n",
            "Accel.14miles             0\n",
            "Brake.06miles             0\n",
            "Brake.08miles             0\n",
            "Brake.09miles             0\n",
            "Brake.11miles             0\n",
            "Brake.12miles             0\n",
            "Brake.14miles             0\n",
            "Left.turn.intensity08     0\n",
            "Left.turn.intensity09     0\n",
            "Left.turn.intensity10     0\n",
            "Left.turn.intensity11     0\n",
            "Left.turn.intensity12     0\n",
            "Right.turn.intensity08    0\n",
            "Right.turn.intensity09    0\n",
            "Right.turn.intensity10    0\n",
            "Right.turn.intensity11    0\n",
            "Right.turn.intensity12    0\n",
            "NB_Claim                  0\n",
            "AMT_Claim                 0\n",
            "dtype: int64\n",
            "Shape of preprocessed data: (100000, 58)\n",
            "Preprocessing completed and saved to 'telematics_syn_preprocessed.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "df_preprocessed = pd.read_csv('telematics_syn_preprocessed.csv')\n",
        "\n",
        "# Split the dataset into train (70%), validation (15%), and test (15%) sets\n",
        "train_size = 0.7\n",
        "val_size = 0.15\n",
        "test_size = 0.15\n",
        "\n",
        "# Split the data into train and temp sets (train + validation + test)\n",
        "train_df, temp_df = train_test_split(df_preprocessed, train_size=train_size, random_state=42)\n",
        "\n",
        "# Split the temp set into validation and test sets\n",
        "val_df, test_df = train_test_split(temp_df, test_size=test_size/(val_size + test_size), random_state=42)\n",
        "\n",
        "# Print the sizes of each set\n",
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")\n",
        "\n",
        "# Save the splits to CSV files (optional)\n",
        "train_df.to_csv('telematics_train.csv', index=False)\n",
        "val_df.to_csv('telematics_val.csv', index=False)\n",
        "test_df.to_csv('telematics_test.csv', index=False)\n",
        "\n",
        "print(\"Dataset splits saved to 'telematics_train.csv', 'telematics_val.csv', and 'telematics_test.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_Xx1N1e6WSU",
        "outputId": "29efa3d7-c9d6-44d9-bc3c-60071f061911"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n",
            "Dataset splits saved to 'telematics_train.csv', 'telematics_val.csv', and 'telematics_test.csv'\n"
          ]
        }
      ]
    }
  ]
}