{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCc583w2VnZ7KSvPFVcUMw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Artificial_Intelligence_Learning/blob/master/soft_computing_alphabet_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6RylE-aE9fj",
        "outputId": "85dfcfdf-5be3-4cd0-f633-18df60f33385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 1.0\n",
            "a belongs to the lowercase alphabet\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Sample dataset of alphabets\n",
        "data = {\n",
        "    'character': ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'],\n",
        "    'label': ['lowercase'] * 26\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Feature extraction\n",
        "vectorizer = CountVectorizer(analyzer='char')\n",
        "X = vectorizer.fit_transform(df['character'])\n",
        "\n",
        "# Target variable\n",
        "y = df['label']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model accuracy: {accuracy}\")\n",
        "\n",
        "# Recognize alphabet function\n",
        "def recognize_alphabet(input_char):\n",
        "    input_vector = vectorizer.transform([input_char])\n",
        "    prediction = model.predict(input_vector)\n",
        "    if prediction[0] == 'lowercase':\n",
        "        print(f\"{input_char} belongs to the lowercase alphabet\")\n",
        "    else:\n",
        "        print(f\"{input_char} does not belong to the lowercase alphabet\")\n",
        "\n",
        "# Test the recognition function\n",
        "input_char = 'a'\n",
        "recognize_alphabet(input_char)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Read the text file\n",
        "file_path = '/content/fars.txt'\n",
        "with open(content/fars.txt, 'r') as file:\n",
        "    data = file.read().splitlines()\n",
        "\n",
        "# Create a pandas dataframe from the data\n",
        "df = pd.DataFrame(data, columns=['character'])\n",
        "\n",
        "# Add labels to the dataframe\n",
        "df['label'] = df['character'].apply(lambda x: 'lowercase' if x.islower() else 'uppercase')\n",
        "\n",
        "# Feature extraction\n",
        "vectorizer = CountVectorizer(analyzer='char')\n",
        "X = vectorizer.fit_transform(df['character'])\n",
        "\n",
        "# Target variable\n",
        "y = df['label']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model accuracy: {accuracy}\")\n",
        "\n",
        "# Recognize alphabet function\n",
        "def recognize_alphabet(input_char):\n",
        "    input_vector = vectorizer.transform([input_char])\n",
        "    prediction = model.predict(input_vector)\n",
        "    if prediction[0] == 'lowercase':\n",
        "        print(f\"{input_char} belongs to the lowercase alphabet\")\n",
        "    else:\n",
        "        print(f\"{input_char} belongs to the uppercase alphabet\")\n",
        "\n",
        "# Test the recognition function\n",
        "input_char = 'a'\n",
        "recognize_alphabet(input_char)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "LoW5Djy_F7nh",
        "outputId": "4d4b2817-2b6b-4f62-eaba-852d99f37d71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4469f55028f9>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Read the text file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/fars.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'content' is not defined"
          ]
        }
      ]
    }
  ]
}